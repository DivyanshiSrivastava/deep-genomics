{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD, Adagrad, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import read\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_yaml\n",
    "from keras import backend as K\n",
    "print K.backend()\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(Reshape((n, 4), input_shape=(n*4,)))\n",
    "    \n",
    "    model.add(Conv1D(32, 20, padding=\"same\", input_shape=(n, 4,)))\n",
    "    print model.input_shape\n",
    "    print model.output_shape\n",
    "    model.add(Activation('relu'))\n",
    "    print model.output_shape\n",
    "    model.add(MaxPooling1D(padding=\"same\", strides=None, pool_size=200))\n",
    "\n",
    "    # after Max Pooling\n",
    "    print model.output_shape\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print model.output_shape\n",
    "    model.add(Dense(512))\n",
    "\n",
    "    # Flattened \n",
    "    print model.output_shape\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Finally\n",
    "    print model.output_shape\n",
    "\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_test(X_train, y_train, X_test, y_test, n):\n",
    "\n",
    "    model = keras_model()\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    adagrad = Adagrad(lr=0.05, epsilon=1e-08, decay=0.0)\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "    hist = model.fit(X_train, y_train, validation_split=0.1, callbacks=[early_stopping], batch_size= 200, nb_epoch= 20)\n",
    "    #hist = model.fit(X_train, y_train, validation_split=0.1, batch_size= 200, shuffle = False, nb_epoch= 10)\n",
    "    print hist.history\n",
    "    probas = model.predict_on_batch(X_test_rs)\n",
    "    print sklearn.metrics.average_precision_score(y_test, probas)\n",
    "    np.savetxt(\"probas\", probas)\n",
    "    print \"Done\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "n = 200\n",
    "X,y = read.get_matrix(\"shared.genomicnegs.txt\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K.image_data_format()\n",
    "X_train_rs = np.reshape(X_train, (-1,200,4))\n",
    "X_test_rs = np.reshape(X_test, (-1,200,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ..., 0 0 1]\n",
      " [0 1 0 ..., 1 0 0]\n",
      " [0 0 1 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 1 0 ..., 1 0 0]\n",
      " [0 1 0 ..., 1 0 0]]\n",
      "[0 0 1 ..., 0 1 1]\n",
      "Start\n",
      "(None, 200, 4)\n",
      "(None, 200, 32)\n",
      "(None, 200, 32)\n",
      "(None, 1, 32)\n",
      "(None, 32)\n",
      "(None, 512)\n",
      "(None, 1)\n",
      "Train on 59482 samples, validate on 6610 samples\n",
      "Epoch 1/20\n",
      "59482/59482 [==============================] - 8s - loss: 0.6652 - acc: 0.5887 - val_loss: 0.6340 - val_acc: 0.6346\n",
      "Epoch 2/20\n",
      "59482/59482 [==============================] - 8s - loss: 0.5283 - acc: 0.7373 - val_loss: 0.4004 - val_acc: 0.8340\n",
      "Epoch 3/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.3501 - acc: 0.8499 - val_loss: 0.3320 - val_acc: 0.8514\n",
      "Epoch 4/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.3126 - acc: 0.8650 - val_loss: 0.3331 - val_acc: 0.8520\n",
      "Epoch 5/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2911 - acc: 0.8763 - val_loss: 0.2994 - val_acc: 0.8723\n",
      "Epoch 6/20\n",
      "59482/59482 [==============================] - 8s - loss: 0.2797 - acc: 0.8820 - val_loss: 0.3262 - val_acc: 0.8604\n",
      "Epoch 7/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2700 - acc: 0.8857 - val_loss: 0.3013 - val_acc: 0.8710\n",
      "Epoch 8/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2614 - acc: 0.8911 - val_loss: 0.2802 - val_acc: 0.8826\n",
      "Epoch 9/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2532 - acc: 0.8953 - val_loss: 0.3055 - val_acc: 0.8687\n",
      "Epoch 10/20\n",
      "59482/59482 [==============================] - 8s - loss: 0.2472 - acc: 0.8985 - val_loss: 0.2714 - val_acc: 0.8844\n",
      "Epoch 11/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2426 - acc: 0.9001 - val_loss: 0.2674 - val_acc: 0.8856\n",
      "Epoch 12/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2387 - acc: 0.9020 - val_loss: 0.2702 - val_acc: 0.8825\n",
      "Epoch 13/20\n",
      "59482/59482 [==============================] - 8s - loss: 0.2350 - acc: 0.9045 - val_loss: 0.2620 - val_acc: 0.8871\n",
      "Epoch 14/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2313 - acc: 0.9056 - val_loss: 0.2657 - val_acc: 0.8897\n",
      "Epoch 15/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2293 - acc: 0.9069 - val_loss: 0.2546 - val_acc: 0.8927\n",
      "Epoch 16/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2271 - acc: 0.9078 - val_loss: 0.2594 - val_acc: 0.8953\n",
      "Epoch 17/20\n",
      "59482/59482 [==============================] - 8s - loss: 0.2247 - acc: 0.9094 - val_loss: 0.2526 - val_acc: 0.8970\n",
      "Epoch 18/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2237 - acc: 0.9081 - val_loss: 0.2571 - val_acc: 0.8943\n",
      "Epoch 19/20\n",
      "59482/59482 [==============================] - 8s - loss: 0.2196 - acc: 0.9112 - val_loss: 0.2494 - val_acc: 0.8962\n",
      "Epoch 20/20\n",
      "59482/59482 [==============================] - 7s - loss: 0.2208 - acc: 0.9103 - val_loss: 0.2511 - val_acc: 0.8986\n",
      "{'acc': [0.58874953884166314, 0.73726505421104305, 0.84987054838825904, 0.8650179895370731, 0.87628189898391795, 0.88203153689272129, 0.88573013322867455, 0.89105947837316213, 0.8952792406338681, 0.89852392229579015, 0.90013785482050168, 0.90197034358280836, 0.90450892638496394, 0.90563531748997828, 0.90687938982234473, 0.90775360624317458, 0.90936754073593562, 0.90812346628120211, 0.91118321613843611, 0.91034262582596093], 'loss': [0.66515593087279179, 0.5283281882293992, 0.35014865547493751, 0.31259584061628326, 0.29107542104560902, 0.27973796540633211, 0.27001936609166394, 0.2613575132916624, 0.25322458443610879, 0.24716055219962496, 0.2425937103357774, 0.23871487480482759, 0.23495562020513261, 0.23132315577469373, 0.22928851109621468, 0.22708828946632703, 0.22472122420065302, 0.22368006210056832, 0.21955217861861862, 0.22076326645734126], 'val_acc': [0.63464447788319323, 0.83403933372872685, 0.85143721734882305, 0.85204236211646889, 0.87231467368923765, 0.86036308937101613, 0.87095310161405903, 0.88260211616348749, 0.86868380941168799, 0.88441754379359028, 0.88562783188610683, 0.88245083218082543, 0.88714069335435419, 0.88971255171858055, 0.89273826563773107, 0.89531013121583281, 0.89697427486327341, 0.8942511253025095, 0.89621784773608737, 0.89863842211765166], 'val_loss': [0.63398215621033527, 0.40044827184410209, 0.33201116427170529, 0.33309593233146034, 0.2993660119901807, 0.32624630636779334, 0.30133942247519152, 0.28019142637815492, 0.30549426246068123, 0.27143959383199867, 0.26735161555967607, 0.27021902364519468, 0.26200739130851181, 0.26567687125772282, 0.25455683131621931, 0.25936437469206852, 0.25256625512183706, 0.25712393551118073, 0.24940771290556205, 0.25109613893071753]}\n",
      "0.942413870889\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print X_train\n",
    "print y_train\n",
    "\n",
    "print \"Start\"\n",
    "model = train_and_test(X_train_rs, y_train, X_test_rs, y_test, n)\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained miodel\n",
      "<keras.models.Sequential object at 0x119d2f550>\n",
      "{'activation': 'sigmoid', 'trainable': True, 'name': 'activation_6'}\n"
     ]
    }
   ],
   "source": [
    "# Trained\n",
    "print \"trained miodel\"\n",
    "print model\n",
    "print model.layers[-1].get_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Using the fucntional API. This method returns a function to find saliency given input and learning phase. \n",
    "def compile_saliency_function(model):\n",
    "    \n",
    "    inp = model.layers[0].input\n",
    "    outp = model.layers[-1].output\n",
    "    print inp\n",
    "    print outp\n",
    "    max_output = K.max(outp, axis=1)\n",
    "    print max_output\n",
    "    saliency = K.gradients(K.sum(max_output), inp)[0]\n",
    "    print saliency\n",
    "    return K.function([inp, K.learning_phase()], [saliency])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv1d_2_input:0\", shape=(?, 200, 4), dtype=float32)\n",
      "Tensor(\"activation_6/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"Max:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"gradients_2/conv1d_2/convolution/ExpandDims_grad/Reshape:0\", shape=(?, 200, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## saliency_fn on the given model. \n",
    "saliency_fn = compile_saliency_function(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 4)\n",
      "(4, 200)\n"
     ]
    }
   ],
   "source": [
    "## Computing Saliency. \n",
    "n = 200\n",
    "test_seq,_= read.get_matrix(\"class.B.txt\")\n",
    "test_seq_rs = np.reshape(test_seq, (-1,200,4))\n",
    "\n",
    "arr_sal = saliency_fn([X_train_rs[:10], 0])\n",
    "outp = (np.asarray(arr_sal))[0][8]\n",
    "print outp.shape\n",
    "\n",
    "ta = np.transpose(outp)\n",
    "print ta.shape\n",
    "np.savetxt(\"check_saliency\",ta)\n",
    "\n",
    "# Need to do a grad * input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4, 64)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "## Interpreting Fitlers.\n",
    "W,b = model.layers[0].get_weights()\n",
    "print W.shape\n",
    "print b.shape\n",
    "\n",
    "# dim1 = filter length\n",
    "# dim2 = A,T,G,C\n",
    "# dim3 = filter number\n",
    "\n",
    "\n",
    "def get_filter(nb, W):\n",
    "    A = list()\n",
    "    T = list()\n",
    "    G = list()\n",
    "    C = list()\n",
    "    for position in range(20):\n",
    "        A.append(W[position][0][nb])\n",
    "        T.append(W[position][1][nb])\n",
    "        G.append(W[position][2][nb])\n",
    "        C.append(W[position][3][nb])\n",
    "        filter_cnn = np.vstack((A,T,G,C))\n",
    "        # So these are the weights of the 4 channels for the first filter\n",
    "        np.savetxt(\"filter\" + str(nb), filter_cnn)\n",
    "\n",
    "for i in range(64):\n",
    "    get_filter(i,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Serialising model to yaml\n",
    "yamlstr = model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Saving model as yaml file. (Switch to json. Was using yaml for deeplift compatibility but that doesn't work \n",
    "# for me yet anyway. )\n",
    "with open(\"CTCF_model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(yamlstr)\n",
    "print \"Done\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
